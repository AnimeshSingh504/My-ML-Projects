{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTPFN0zF843q"
   },
   "source": [
    "# Using Inbuilt Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Cm-W5-Br8431"
   },
   "outputs": [],
   "source": [
    "#Various models required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os,sys\n",
    "from sklearn import model_selection\n",
    "import re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WdxOGwuF8437"
   },
   "outputs": [],
   "source": [
    "#This are stop_words in common taken from intenet.\n",
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "AxFmZK5j8439",
    "outputId": "077c090a-4982-4994-c80d-db64ec8e9437"
   },
   "outputs": [],
   "source": [
    "#X is a list further made in form of tuple , where first element is name of document and second is the text in documents.\n",
    "#Y is the category\n",
    "\n",
    "#change the path of dataset as required\n",
    "X  =[] \n",
    "Y = []\n",
    "for category in os.listdir(r\"C:\\Users\\ANIMESH\\20_newsgroups\"):\n",
    "    for document in os.listdir(r\"C:\\Users\\ANIMESH\\20_newsgroups\"+category):\n",
    "        with open(r\"C:\\Users\\ANIMESH\\20_newsgroups\"+category+'/'+document, \"r\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm5MErdU843_"
   },
   "outputs": [],
   "source": [
    "#DataType of X and Y in detail\n",
    "print(type(X))\n",
    "print(type(X[0]))\n",
    "print(type(X[0][0]))\n",
    "print(type(X[0][1]))\n",
    "print(type(Y))\n",
    "#We can see it is a tuple with first element as name of document and second text of document.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkSZKGwJ844B"
   },
   "outputs": [],
   "source": [
    "#splitting the data in training and testing\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "JsjfJWi_844D",
    "outputId": "0442555b-d2dd-449c-ee3e-7373f22519ec"
   },
   "outputs": [],
   "source": [
    "#split has done in nearly 3:1 ratio\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfCymU-A844F",
    "outputId": "e5fece86-b8b3-4de9-cdc8-24e77a3f7b54"
   },
   "outputs": [],
   "source": [
    "#Example for showing re.split\n",
    "sample_text=\"Hey! I am Abhishek. I am superb. What are you doing there?\"\n",
    "print(re.split(r'\\W+',sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OFSJ5NS844I"
   },
   "outputs": [],
   "source": [
    "#Making Dictionary of words with their corresponding frequency\n",
    "dic={}\n",
    "for i in range(len(x_train)):\n",
    "    #Took [1] because [0] is name of doc and [1] is text in doc\n",
    "    word=x_train[i][1].lower()\n",
    "    #splitting the text into words\n",
    "    stripped=re.split(r'\\W+',word)\n",
    "    #Iterating over each word\n",
    "    for s in stripped:\n",
    "        #we will not include stop_words, alpha-numerics, punctuations or irrelevant word of length less than 2 in our dictionary\n",
    "        if not(s.isalpha()) or s in stop_word or len(s)<=2:\n",
    "            continue\n",
    "        if s in dic:\n",
    "            dic[s]+=1\n",
    "        else:\n",
    "            dic[s]=1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJoegrJs844M"
   },
   "outputs": [],
   "source": [
    "#Sorting the dictionary on basis of frequency of words in descending order\n",
    "sorted_dic = sorted(dic.items(), key=operator.itemgetter(1),reverse=True)\n",
    "sorted_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RMA0r8P844O"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hwAUiYS844P"
   },
   "outputs": [],
   "source": [
    "#Plotting graph on no. of words vs frequency \n",
    "#On basis of graph we can decide the number of features we want to take\n",
    "features=sorted_dic\n",
    "answer1=[]\n",
    "answer2=[]\n",
    "for i in range(len(features)):\n",
    "    answer1.append(i)\n",
    "    answer2.append(features[i][1])\n",
    "plt.plot(answer1,answer2)\n",
    "plt.axis([0,8000,1,5000])\n",
    "plt.grid()\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_rYjuS2844Q"
   },
   "outputs": [],
   "source": [
    "#We decided to take top 2000 words with max freuqency as our feature\n",
    "#here feature list is answer1\n",
    "answer1=[features[i][0] for i in range(2000)]\n",
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8HDghuh844R"
   },
   "outputs": [],
   "source": [
    "#Making x_train dataset\n",
    "#No. of rows is equivalent to rows in x_train, and column is equal to length of answer1(feature list)\n",
    "x_train_dataset=np.zeros([len(x_train),len(answer1)],int)\n",
    "for i in range(len(x_train)):\n",
    "    words=x_train[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our answer1(feature list)\n",
    "        if j in answer1:\n",
    "            x_train_dataset[i][answer1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6XjewOT844S"
   },
   "outputs": [],
   "source": [
    "#Making x_test dataset\n",
    "#No. of rows is equivalent to rows in x_test, and column is equal to length of answer1(feature list)\n",
    "x_test_dataset=np.zeros([len(x_test),len(answer1)],int)\n",
    "for i in range(len(x_test)):\n",
    "    words=x_test[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our answer1(feature list)\n",
    "        if j in answer1:\n",
    "            x_test_dataset[i][answer1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_sNYANM844T"
   },
   "outputs": [],
   "source": [
    "#printing x_train and x_test dataset \n",
    "print(x_train_dataset)\n",
    "print(\"--------------------------\")\n",
    "print(x_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKT2aYo3844U"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yma_vRVw844U"
   },
   "outputs": [],
   "source": [
    "#Demonstrating confusion-matrix and classification report\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_dataset,y_train)\n",
    "y_pred=clf.predict(x_test_dataset)\n",
    "print(\"Score on training data:\",clf.score(x_train_dataset,y_train))\n",
    "print(\"Score on testing data:\",clf.score(x_test_dataset,y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AM6lCJM844W"
   },
   "source": [
    "# Self Implementation of Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lCJ7zYn844W"
   },
   "outputs": [],
   "source": [
    "#Making dictionary for implementing Naive Baye's\n",
    "def fit(x_train_dataset,y_train):\n",
    "    count={}\n",
    "    total_word=0\n",
    "    y_train=np.array(y_train)\n",
    "    #Total no. of document is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for i in classes:\n",
    "        temp=0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_dataset[y_train==i]\n",
    "        #finding length of data with category corresponding to i \n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over answer1(actual feature list)\n",
    "        for feature in answer1:\n",
    "            #Calculating total word in feature\n",
    "            l=(x_train_with_i[:,answer1.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=l\n",
    "        #Total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #Length of data with y_train belonging to specific class\n",
    "        count[i][\"length\"]=temp2\n",
    "        \n",
    "    \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d7xax8Z844X"
   },
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classes):\n",
    "    prob=np.log(dic[classes][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classes].keys())\n",
    "    #-2 is done becuase there will be \"length\" and \"word in class\" present in feature. \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #If frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #Extra addition part is Laplace correction\n",
    "            num=dic[classes][feature[j]]+1\n",
    "            den=dic[classes][\"word_in_class\"]+len(dic[classes].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIuxOZvX844Y"
   },
   "outputs": [],
   "source": [
    "#Best_class or probable answer will be returned from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run=True\n",
    "    classes=dic.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rflFn8Ny844Y"
   },
   "outputs": [],
   "source": [
    "def predict_(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5J2Uagzy844Z"
   },
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NjkmEEE844a"
   },
   "outputs": [],
   "source": [
    "#This cell will take time to execute\n",
    "dictionary=fit(x_train_dataset,y_train)\n",
    "y_pred=predict_(x_test_dataset,dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8N0RiAz844a"
   },
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3GBxbv3844b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYanQ06b844b"
   },
   "outputs": [],
   "source": [
    "print(\"Score on testing_data:\",score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rabd5Gz844c"
   },
   "source": [
    "RESULT:\n",
    "\n",
    "We have performed Text Classification using Naive Bayes both by sklearn and self implementation.\n",
    "\n",
    "We found out that sklearn gave score of 0.86 on testing_data,whereas self implemented classifier gave 0.87 on testing data,which is very close to sklearn Implementation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
